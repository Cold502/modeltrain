================================================================================
五、 系统测试
================================================================================

（一）测试目的

系统测试是软件开发生命周期中的重要环节，其目的在于全面验证系统是否满足需求规格说明的要求，确保系统在实际运行环境中的稳定性、可靠性和安全性。本次测试主要关注以下几个方面：

1. 功能完整性验证：检验系统各功能模块是否按照需求规格正确实现，确保功能无遗漏、无错误。

2. 性能指标评估：测试系统在不同负载下的响应时间、并发处理能力、流式响应性能等，确保系统满足性能需求。

3. 安全性保障：验证JWT认证机制、权限控制、SQL注入防护等安全措施是否有效，确保系统数据和用户隐私安全。

4. 用户体验评价：通过实际操作测试，评估系统界面友好性、操作流畅性、错误提示准确性等用户体验指标。

通过系统测试，发现并修复系统缺陷，为系统正式上线提供质量保证和决策依据。

（二）测试环境

1. 硬件环境

服务器硬件配置如下：

设备类型	配置项	配置参数
应用服务器	CPU	Intel Core i7-12700K @ 3.60GHz
	内存	32 GB DDR4
	硬盘	1 TB NVMe SSD
	GPU	NVIDIA RTX 4090 24GB
	操作系统	Windows 11 Pro
数据库服务器	CPU	Intel Core i7-12700K @ 3.60GHz
	内存	32 GB DDR4
	硬盘	512 GB NVMe SSD
	操作系统	Windows 11 Pro
客户端	CPU	Intel Core i5 @ 2.5GHz
	内存	16 GB
	操作系统	Windows 10/11
	浏览器	Chrome 120、Edge 120、Firefox 121
表5-2-1 硬件环境配置

2. 软件环境

系统软件配置如下：

组件类型	软件名称	版本
后端运行环境	Python	3.14
	FastAPI	0.100+
	Uvicorn	0.23+
	SQLAlchemy	2.0+
前端运行环境	Node.js	24.10.0
	npm	10.x
	Vite	7.1.4
	Vue	3.3.0
	Element Plus	2.4.0
数据库	SQLite	3.x（开发环境）
	MySQL	8.0（生产环境）
可视化工具	SwanLab	最新版本
测试工具	Postman	10.x
	JMeter	5.6
	Chrome DevTools	内置
表5-2-2 软件环境配置

（三）功能测试

功能测试采用黑盒测试方法，根据需求规格说明书设计测试用例，验证系统各功能模块的正确性。

1. 用户认证测试

测试用例	测试步骤	预期结果	测试结果
用户注册-正常流程	1. 访问注册页面
2. 输入邮箱admin@test.com、昵称testuser、密码Test123!
3. 点击注册按钮	注册成功，跳转到登录页面	通过
用户注册-邮箱重复	1. 使用已存在的邮箱admin@test.com注册	提示"邮箱已被注册"	通过
用户注册-昵称重复	1. 使用已存在的昵称admin注册	提示"昵称已被使用"	通过
用户登录-正确凭证	1. 输入邮箱admin和密码admin
2. 点击登录按钮	登录成功，生成Access Token和Refresh Token，跳转到首页	通过
用户登录-错误密码	1. 输入正确邮箱和错误密码	提示"用户名或密码错误"	通过
用户登录-不存在用户	1. 输入不存在的邮箱	提示"用户名或密码错误"	通过
Token刷新	1. Access Token过期后自动刷新	前端自动使用Refresh Token获取新Access Token，无感刷新	通过
登出功能	1. 点击登出按钮	清除Token，跳转到登录页面	通过
表5-3-1 用户认证测试用例

2. 模型配置测试

测试用例	测试步骤	预期结果	测试结果
添加模型配置-正常流程	1. 点击"添加模型配置"
2. 选择提供商OpenAI，输入API地址和API Key
3. 点击"刷新模型列表"
4. 选择模型gpt-4，配置参数
5. 保存配置	配置成功，模型列表显示新配置	通过
刷新模型列表	1. 在配置对话框中点击"刷新模型列表"	从提供商API获取模型列表并展示	通过
编辑模型配置	1. 点击某个配置的编辑按钮
2. 修改配置参数
3. 保存修改	配置更新成功	通过
删除模型配置	1. 点击某个配置的删除按钮
2. 确认删除	配置删除成功，列表中不再显示该配置	通过
重复配置检测	1. 添加与已有配置相同的模型配置	提示"相同的模型配置已存在"	通过
表5-3-2 模型配置测试用例

3. 模型对话测试

测试用例	测试步骤	预期结果	测试结果
创建新会话	1. 点击"新对话"按钮	创建新会话，会话列表显示新会话	通过
发送消息	1. 在输入框输入消息"你好"
2. 选择模型
3. 点击发送	消息发送成功，模型返回响应	通过
流式响应	1. 发送消息并启用流式响应	模型响应逐字展示，支持Markdown渲染	通过
思维链展示	1. 使用DeepSeek R1模型发送消息	解析并展示<think>标签中的推理过程	通过
切换会话	1. 在会话列表中点击其他会话	切换到选中的会话，加载历史消息	通过
删除会话	1. 点击会话的删除按钮
2. 确认删除	会话删除成功，包含的所有消息一并删除	通过
导出会话-TXT	1. 点击"导出会话"，选择TXT格式	生成TXT文件并下载	通过
导出会话-Markdown	1. 点击"导出会话"，选择Markdown格式	生成Markdown文件并下载，保留格式	通过
导出会话-JSON	1. 点击"导出会话"，选择JSON格式	生成JSON文件并下载，包含完整元数据	通过
表5-3-3 模型对话测试用例

4. 模型训练测试

测试用例	测试步骤	预期结果	测试结果
上传数据集-正常流程	1. 点击"上传数据集"
2. 选择JSON格式数据文件
3. 填写数据集名称和描述
4. 上传	数据集上传成功，列表显示新数据集	通过
上传数据集-格式错误	1. 上传不支持的文件格式（如.xlsx）	提示"不支持的文件格式"	通过
创建训练任务	1. 点击"创建训练任务"
2. 填写任务名称
3. 选择基座模型和数据集
4. 配置训练参数（学习率、Epoch等）
5. 创建	任务创建成功，状态为"待运行"	通过
启动训练任务	1. 点击任务的"启动"按钮	任务状态变为"运行中"，SwanLab服务启动	通过
查看训练日志	1. 点击运行中任务的"查看日志"	显示实时训练日志，自动滚动	通过
停止训练任务	1. 点击运行中任务的"停止"按钮
2. 确认停止	任务停止，状态变为"失败"或"已完成"	通过
SwanLab监控	1. 在训练可视化页面查看SwanLab	显示训练Loss、学习率等指标曲线	通过
表5-3-4 模型训练测试用例

（四）性能测试

性能测试使用Apache JMeter工具，模拟多用户并发访问，测试系统在不同负载下的响应时间和稳定性。

1. 并发用户测试

测试场景为200个并发用户同时登录系统，执行登录操作，重复5次取平均值。

并发用户数	平均响应时间（秒）	最小响应时间（秒）	最大响应时间（秒）	标准偏差	事务成功率
50	0.156	0.089	0.312	0.045	100%
100	0.234	0.125	0.487	0.078	100%
150	0.312	0.187	0.623	0.112	100%
200	0.421	0.245	0.798	0.145	100%
表5-4-1 登录并发测试结果

测试结果表明，系统在200个并发用户同时登录时，平均响应时间为0.421秒，满足性能需求（小于0.5秒）。事务成功率达到100%，系统运行稳定。

2. 响应时间测试

测试各核心API接口的响应时间，每个接口执行100次取平均值。

接口名称	请求方法	平均响应时间（ms）	最小响应时间（ms）	最大响应时间（ms）	是否满足需求
用户登录	POST /api/auth/login	156	89	312	是（<300ms）
获取模型配置列表	GET /api/model-configs	89	45	178	是（<300ms）
创建会话	POST /api/chat/sessions	134	78	245	是（<300ms）
发送消息（非流式）	POST /api/chat/messages	245	156	456	是（<300ms）
获取训练任务列表	GET /api/training/tasks	123	67	234	是（<300ms）
上传数据集	POST /api/training/datasets	1245	892	2134	是（<3s）
表5-4-2 API响应时间测试结果

测试结果表明，所有核心API接口的平均响应时间均控制在300ms以内，满足系统性能需求。数据集上传接口响应时间稍长，但考虑到文件上传的特殊性，1.2秒的响应时间仍在可接受范围内。

3. 流式响应性能测试

测试SSE流式响应的性能指标，包括首Token时间（TTFT）和系统引入的额外延迟。

测试指标	测试值	需求值	是否满足
首Token时间（TTFT）	120-350ms	取决于模型	是
系统引入的额外延迟	35ms	<50ms	是
流式传输稳定性	无丢包、无中断	稳定传输	是
并发流式请求支持数	50+	>20	是
表5-4-3 流式响应性能测试结果

测试结果表明，系统流式响应性能优秀，系统自身引入的额外延迟仅为35ms，远低于50ms的需求上限。支持50个以上并发流式请求，满足实际使用需求。

（五）安全性测试

安全性测试验证系统在身份认证、权限控制、数据保护等方面的安全措施是否有效。

1. JWT认证测试

测试用例	测试步骤	预期结果	测试结果
无Token访问	1. 不携带Token访问需要认证的API	返回401错误，提示"未认证"	通过
伪造Token访问	1. 使用伪造的Token访问API	返回401错误，Token验证失败	通过
过期Token访问	1. 使用过期的Access Token访问API	返回401错误，提示"Token已过期"	通过
Refresh Token刷新	1. 使用有效的Refresh Token刷新Access Token	返回新的Access Token	通过
过期Refresh Token	1. 使用过期的Refresh Token刷新	返回401错误，要求重新登录	通过
Token时效性验证	1. 验证Access Token 15分钟有效期
2. 验证Refresh Token 7天有效期	Token在有效期内可用，过期后自动失效	通过
表5-5-1 JWT认证测试用例

2. 权限控制测试

测试用例	测试步骤	预期结果	测试结果
普通用户访问管理功能	1. 普通用户尝试访问用户管理页面	返回403错误，提示"需要管理员权限"	通过
普通用户访问其他用户数据	1. 普通用户A尝试访问用户B的会话	返回404错误或403错误	通过
管理员访问管理功能	1. 管理员访问用户管理、系统统计等功能	正常访问，显示所有数据	通过
会话权限验证	1. 用户只能访问自己创建的会话	只能看到和操作自己的会话	通过
训练任务权限验证	1. 用户只能管理自己创建的训练任务	只能看到和操作自己的任务	通过
表5-5-2 权限控制测试用例

3. SQL注入测试

测试用例	测试步骤	预期结果	测试结果
登录表单SQL注入	1. 在登录表单中输入SQL注入语句
如：' OR '1'='1	参数化查询防止注入，登录失败	通过
搜索框SQL注入	1. 在搜索框中输入SQL注入语句	ORM框架自动转义，查询安全	通过
URL参数SQL注入	1. 在URL参数中添加SQL注入语句	参数验证和ORM保护，注入无效	通过
密码存储安全	1. 查看数据库中的密码字段	密码使用bcrypt加密存储，不可逆	通过
API Key存储安全	1. 查看数据库中的API Key字段	API Key加密存储	通过
表5-5-3 SQL注入测试用例

（六）测试结果分析

通过对系统进行全面的功能测试、性能测试和安全性测试，得出以下结论：

1. 功能完整性：系统各功能模块均按照需求规格正确实现，功能测试通过率达到100%。用户认证、模型配置、模型对话、模型对比测试、模型训练、训练可视化、提示词管理、系统管理等8个核心模块均运行正常，无功能遗漏和严重缺陷。

2. 性能表现：系统性能指标均满足需求。在200个并发用户场景下，平均响应时间为0.421秒，核心API接口响应时间控制在300ms以内。流式响应系统引入的额外延迟仅为35ms，远低于50ms的需求上限。系统支持50个以上并发流式请求，满足实际使用场景。

3. 安全保障：系统安全措施有效。JWT双令牌认证机制运行稳定，Token时效性控制准确。权限控制严格，普通用户无法访问管理功能和其他用户数据。密码和API Key均加密存储，SQLAlchemy ORM有效防止SQL注入攻击。

4. 用户体验：系统界面简洁友好，符合Element Plus设计规范。操作流程清晰，错误提示准确。流式响应实时展示，思维链可视化功能运行良好。导出功能支持多种格式，满足不同使用需求。

5. 存在问题：
   - 数据集上传接口响应时间稍长（1.2秒），但考虑文件上传特性，仍在可接受范围。
   - 系统暂未实现完整的日志审计功能，建议在后续版本中补充。
   - 训练任务的错误恢复机制需要进一步完善。

6. 改进建议：
   - 优化数据集上传性能，考虑分片上传大文件。
   - 增加系统操作日志记录功能，便于问题追溯。
   - 完善训练任务的断点续训功能，提高训练稳定性。
   - 增加API调用限流机制，防止恶意请求。

综上所述，本系统功能完整、性能优秀、安全可靠，满足企业大语言模型训练与应用管理的需求，可以投入生产环境使用。
